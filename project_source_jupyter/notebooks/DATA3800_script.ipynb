{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a114f243-4390-4d94-a93d-5cb18bd40881",
   "metadata": {},
   "source": [
    "# DATA3800 - Introduction to data science with scripting\n",
    "## Predictively modeling salmon louse counts in fish farming - *project code*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7e4d2-4615-4962-83e5-0ae600c08f0a",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains all the code for the project in a runnable format. Note that the descriptions of the various steps is not as in-depth her, since I covered that in the report.\n",
    "\n",
    "Running R in a Jupyter notebook can be a bit finicky, since it requires that we run both a `venv` (Python virtual environment) and a `renv` (R virtual environment). R also doesn't like a nested project structure, so there are a few extra steps involved with getting the IRkernel to recognise the renv. I have done my best to make sure everything is in order, but just in case the Jupyter notebook isn't cooperative, I have also included the raw R script file under the `backup_script/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5277849-a9ef-43f6-8ebb-16a01f8499e5",
   "metadata": {},
   "source": [
    "### Preparations - Load packages, source data, and set seed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ba05a-2ee2-4bce-9417-76fa2f9b0817",
   "metadata": {},
   "source": [
    "I start by loading the necessary packages for running the script. Several additional packages will be called directly using the `package_name::function_name()` syntax. I've told the `library()` function to load packages quietly for the sake of clarity, since the outputs can take a lot of space when viewed in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bacb5a-1679-4ded-b9cd-e5f80889cffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(dplyr, quietly = TRUE): there is no package called ‘dplyr’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(dplyr, quietly = TRUE): there is no package called ‘dplyr’\nTraceback:\n",
      "1. library(dplyr, quietly = TRUE)"
     ]
    }
   ],
   "source": [
    "# Load necessary packages:\n",
    "library(dplyr, quietly = TRUE)\n",
    "library(tidyr, quietly = TRUE)\n",
    "library(stringr, quietly = TRUE)\n",
    "library(lme4, quietly = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10dfe8-90e1-42c8-aad4-6d03593a9a92",
   "metadata": {},
   "source": [
    "By setting a seed (in this case a cheeky reference to the course code) I ensure that the numbers generated by the pseudorandom number generator stay consistent between different sessions (though they may differ between different pseudorandom number generator and the operative systems which use them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b810b862-8aeb-4559-a374-a85b442ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed to ensure reproducibility:\n",
    "set.seed(3800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f6ccf-a9a6-45e7-9315-0cf42bb90631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data files:\n",
    "lice_per_fish  <- readr::read_csv(\"../data/lakselus_per_fisk.csv\")\n",
    "lice_treatment <- readr::read_csv(\"../data/tiltak_mot_lakselus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30fce2e-a6cb-4159-8664-10c4024d67d5",
   "metadata": {},
   "source": [
    "### Data wrangling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411006e6-d571-4c40-8fb8-6bfaf509c8ab",
   "metadata": {},
   "source": [
    "This is where the fun begins. First we must manipulate the data into a usable state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ae5b5-d0fa-4b3e-9d3a-495422e8a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with underscores in all column names and make lowercase:\n",
    "list(lice_per_fish = lice_per_fish,\n",
    "     lice_treatment = lice_treatment) %>% \n",
    "  lapply(function(df) {\n",
    "    rename_all(df, ~tolower(.)) %>%                 # Change to lowercase.\n",
    "    rename_all(.,  ~str_replace_all(., \" \", \"_\"))   # Spaces to underscores.\n",
    "  }) %>% \n",
    "  list2env(envir = .GlobalEnv)  # Save to global environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d572b9-5c86-4a58-b4a3-ae323e9f1a74",
   "metadata": {},
   "source": [
    "Cleanerfish were only recorded until the start of 2019, after which the registrations were discontinued. The first of the code snippets below returns a table view containing the number of times each species of cleanerfish appear within the dataset. The latter snippet returns the number of unique species, or in this case: NA :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b49026-7297-4981-ac2e-f320bbb34e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the presence of cleanerfish species before and after 31. December, 2018:\n",
    "\n",
    "# Before change:\n",
    "lice_treatment %>% \n",
    "  filter(år <= 2018) %>% \n",
    "  select(rensefisk) %>% \n",
    "  table()\n",
    "\n",
    "# After change:\n",
    "lice_treatment %>% \n",
    "  filter(år > 2018) %>% \n",
    "  select(rensefisk) %>% \n",
    "  unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d8665-5612-4874-83ed-a105a6c9f734",
   "metadata": {},
   "source": [
    "Before I can join the two data frames together, I must prepare the data frame 'lice_treatment' for joining. When I `left_join()` `lice_treatment` to `lice_per_fish`, it inserts only rows which matches observations in `lice_per_fish`. In this case, since one farm site can recieve different treatments even within the same week, we get duplicate records when we look at just the shared columns. To deal with this, we combine all the records from the same site, and spread the data out into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff987cdc-34d6-4e32-aa28-dea5f0836e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data frame 'lice_treatment' for joining:\n",
    "lice_treatment <- lice_treatment %>% \n",
    "  select(uke, år, lokalitetsnavn, tiltak) %>% \n",
    "  \n",
    "  # Remove duplicate rows:\n",
    "  distinct() %>% \n",
    "  \n",
    "  # Give each of the treatment categories its own boolean column:\n",
    "  mutate(value = TRUE) %>% \n",
    "  pivot_wider(\n",
    "    names_from = tiltak,  # Column to be split.\n",
    "    values_from = value,\n",
    "    values_fill = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4c2fd-d96f-4f15-8509-b00a1daa53c9",
   "metadata": {},
   "source": [
    "Now we join the two data frames together, before we manipulate the resulting data frame further. The first thing we do after combining the data is removing rows for weeks where a salmon louse count was not carried out, since these observations are irrelevant to the project. Next, we fill the boolean columns created in the last cell with `FALSE` values, so that we don't get any missing data errors later. Finally, we add the columns for cyclically transformed time and the log transformed response variable. Sorting the rows is done just for my convenience in exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2f7d3-f2d6-45c0-9083-b850aab8daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the dataframe 'lice_treatment' to 'lice_per_fish':\n",
    "working_df <- left_join(lice_per_fish,\n",
    "                        lice_treatment) %>% \n",
    "  \n",
    "  # Remove rows with no salmon lice counts:\n",
    "  subset(har_telt_lakselus == \"Ja\") %>% \n",
    "  \n",
    "  # Fill NAs in the newly added boolean columns with FALSE:\n",
    "  mutate_if(is.logical, coalesce, FALSE) %>% \n",
    "  \n",
    "  # Change week 53 to week 52 for all records:\n",
    "  mutate(uke = if_else(uke == 53, 52, uke)) %>% \n",
    "  \n",
    "  # Add variables for cyclic time:\n",
    "  {\n",
    "    # Assign local variable 'angle':\n",
    "    angle = (2 * pi * .$uke) / 52 \n",
    "    \n",
    "    # Calculate flipped sine and cosine transformed values:\n",
    "    mutate(., sin = -sin(angle),\n",
    "              cos = -cos(angle))\n",
    "  } %>%\n",
    "  \n",
    "  # Create the log transformed response variable:\n",
    "  {\n",
    "    const <- 0.01  # Add small constant to handle zeros.\n",
    "    \n",
    "    # NB! log() in R refers to the natural logarithm.\n",
    "    mutate(., log_response = log(voksne_hunnlus + const))\n",
    "  } %>% \n",
    "  \n",
    "  # Arrange rows chronologically:\n",
    "  arrange(år, uke, lokalitetsnavn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faae28eb-d004-4096-95e7-d7f07769452f",
   "metadata": {},
   "source": [
    "To decide on which model to use, I had to explore the data in order to see if it conformed to the model assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab99567-f34d-4217-81b0-1a5341760bef",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f385857-8aa0-4ee5-b220-d5f2fe152507",
   "metadata": {},
   "source": [
    "This is the general syntax to fit a model with `lmer()`, with several fixed effects and `lokalitetsnavn` as a random effect. In this example, for the sake of illustration, I have included each of the considered predictor variables and interaction effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4ce2c-f10b-4947-a8e5-e203fde2f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Linear Mixed Model:\n",
    "model <- lmer(log_response ~ sjøtemperatur +\n",
    "                             lat +\n",
    "                             cos + sin +\n",
    "                             sjøtemperatur * cos +\n",
    "                             sjøtemperatur * sin +\n",
    "                             sjøtemperatur * lat +\n",
    "                             cos * lat +\n",
    "                             sin * lat +\n",
    "                             (1 | lokalitetsnavn),\n",
    "              data = train)\n",
    "\n",
    "# Apply model to the test set:\n",
    "test <- test %>% \n",
    "  # Save the fitted response to a new column:\n",
    "  mutate(fitted_log_response = predict(model, \n",
    "                                       newdata = test,\n",
    "                                       allow.new.levels = TRUE),\n",
    "         \n",
    "         # Back-transform the fitted response to avg. count:\n",
    "         fitted_voksne_hunnlus = exp(fitted_log_response) - 0.01)\n",
    "\n",
    "# Calculate metrics for model performance evaluation: \n",
    "rmse_value <- Metrics::rmse(test$fitted_log_response,  # Root Mean Square Error.\n",
    "                            test$log_response)\n",
    "mae_value  <- Metrics::mae(test$fitted_log_response,   # Mean Absolute Error.\n",
    "                           test$log_response)\n",
    "r_squared  <- MuMIn::r.squaredGLMM(model)              # Approximated R squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea35592-11b4-4606-9571-938b15970d30",
   "metadata": {},
   "source": [
    "To find the best model, we must create and evaluate each candidate model and select the model which prerforms the best. We start by defining candidate models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df63c44-f40b-4969-88b6-9f9fa79ce1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable fixed effects:\n",
    "# NB! Sea temperature is always included.\n",
    "predictors <- c(\n",
    "  \"lat\",\n",
    "  \"cos\",\n",
    "  \"sin\",\n",
    "  \"sjøtemperatur * lat\",\n",
    "  \"sjøtemperatur * cos\",\n",
    "  \"sjøtemperatur * sin\",\n",
    "  \"cos * lat\",\n",
    "  \"sin * lat\"\n",
    ")\n",
    "\n",
    "# Generate combinations of predictors:\n",
    "predictor_combinations <- \n",
    "  lapply(1:length(predictors), \n",
    "         function(n) {\n",
    "           combinations <- gtools::combinations(length(predictors), \n",
    "                                                n, \n",
    "                                                as.character(predictors))\n",
    "           lapply(1:nrow(combinations), \n",
    "                  function(i) combinations[i, ])})\n",
    "\n",
    "# Simplify the data structure:\n",
    "predictor_combinations <- unlist(predictor_combinations, \n",
    "                                 recursive = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77b1ff-90c4-4916-8b18-e508c2b79626",
   "metadata": {},
   "source": [
    "Next, we run the list of potential candidate models through a function to strip away duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54113afd-8103-494f-a830-6f2763ac8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove strings that are substrings of another string:\n",
    "remove_substrings <- function(lst) {\n",
    "  lst[!vapply(seq_along(lst), \n",
    "              function(i) any(grepl(lst[i], \n",
    "                                    lst[-i])), \n",
    "              logical(1))]\n",
    "  }\n",
    "\n",
    "# Apply the function to the combinations of predictors:\n",
    "predictor_combinations <- predictor_combinations %>% \n",
    "  \n",
    "  # Remove substrings:\n",
    "  lapply(remove_substrings) %>% \n",
    "  \n",
    "  # Remove duplicate list entries:\n",
    "  unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eddfe1-93e4-4adb-9637-5731f0784532",
   "metadata": {},
   "source": [
    "Next, we run through the candidate models and save the models to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c465b85-2482-4582-8337-931a49de13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store model results:\n",
    "models <- list()\n",
    "\n",
    "# Iterate through the combinations list and fit models for each combination:\n",
    "# Grab a cup of coffee, this will take a little while!\n",
    "for (combination in predictor_combinations) {\n",
    "  \n",
    "  # Specify the formula based on the list of combinations:\n",
    "  formula <- as.formula(paste(\"log_response ~ sjøtemperatur +\n",
    "                                              (1 | lokalitetsnavn) +\",\n",
    "                              paste(combination, collapse = \" + \")))\n",
    "  \n",
    "  # Run the model:\n",
    "  model <- lmer(formula = formula, data = train)\n",
    "  \n",
    "  # Save the model to the list we created:\n",
    "  models[[paste(c(\"sjøtemperatur\", \n",
    "                  combination), collapse = \" + \")]] <- model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbea511-ae6e-486f-9a8a-124a96b8dedb",
   "metadata": {},
   "source": [
    "Now we run the models through the test set and record the results of the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664b8a8-e3d4-4230-950f-20076f982c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data frame to store the evaluation metrics:\n",
    "model_evaluation <- data.frame(model = names(models),\n",
    "                               rmse  = NA,\n",
    "                               mae   = NA,\n",
    "                               r2m   = NA,\n",
    "                               r2c   = NA)\n",
    "\n",
    "for (i in seq_along(models)) {\n",
    "  \n",
    "  # Run the model through the test set:\n",
    "  prediction <- predict(models[[i]],\n",
    "                        newdata = test,\n",
    "                        allow.new.levels = TRUE)\n",
    "  \n",
    "  # Calculate RMSE:\n",
    "  model_evaluation[i, \"rmse\"] <- Metrics::rmse(prediction,\n",
    "                                             test$log_response)\n",
    "  # Calculate MAE:\n",
    "  model_evaluation[i, \"mae\"] <- Metrics::mae(prediction,\n",
    "                                           test$log_response)\n",
    "  # Calculate R^2:\n",
    "  model_evaluation[i, c(\"r2m\", \"r2c\")] <- MuMIn::r.squaredGLMM(models[[i]]) %>% \n",
    "    as.vector()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21ce13-238b-4745-a481-dd8669accac6",
   "metadata": {},
   "source": [
    "The following block finds the best model according to each metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe91ae-dd5b-4603-990a-3af8199a315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model according to all evaluation metrics:\n",
    "model_evaluation %>%\n",
    "  filter(rmse == min(rmse))  # Find minimum RMSE value.\n",
    "\n",
    "model_evaluation %>%\n",
    "  filter(mae == min(mae))    # Find minimum MAE value.\n",
    "\n",
    "model_evaluation %>%\n",
    "  filter(r2m == max(r2m))    # Find maximum R^2m value.\n",
    "\n",
    "model_evaluation %>%\n",
    "  filter(r2c == max(r2c))    # Find maximum R^2c value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc3879-8a91-4933-a3a1-a07da9303b76",
   "metadata": {},
   "source": [
    "### Plot code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897056a-df02-45f0-8dce-bfc11551a620",
   "metadata": {},
   "source": [
    "The following code produces the visualisation of the sine and cosine transformed cyclic time variables. For the sake of convenience, I have modified to function to output the plot to the default graphics device. Simply comment the relevant sections back in to have it write to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0858a-b97d-4b75-8eb0-12281a386da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualisation of the cyclically transformed time variable:\n",
    "working_df %>% \n",
    "  select(uke, sin, cos) %>% \n",
    "  arrange(uke) %>% \n",
    "  {\n",
    "    # TO WRITE TO FILE, COMMENT IN THIS:\n",
    "      \n",
    "    # # Specify where to save the finished plot:\n",
    "    # pdf(\"../figures/cyclic_time.pdf\",\n",
    "    #     width  = 8,\n",
    "    #     height = 5)\n",
    "    #\n",
    "    # # Adjust padding:\n",
    "    # par(mar = c(4, 4, 2, 2))\n",
    "    \n",
    "    attach(.)  # Lets me select columns by name without indexing.\n",
    "    \n",
    "    # Plot the sin curve:\n",
    "    plot(sin~uke, \n",
    "         type = \"l\", \n",
    "         lwd = 2, \n",
    "         cex.lab = 1.2,\n",
    "         col = \"orange\",\n",
    "         ylab = \"Yearly oscillation\", \n",
    "         xlab = \"Week number\")\n",
    "    \n",
    "    # Plot the cos curve:\n",
    "    lines(cos~uke, \n",
    "          lwd = 2, \n",
    "          col = \"dimgray\")\n",
    "    \n",
    "    # Add a legend:\n",
    "    legend(\"topleft\", \n",
    "           inset = c(0.05,0.08),\n",
    "           legend = c(\"sin 1\", \"cos 1\"), \n",
    "           col = c(\"orange\", \"dimgray\"), \n",
    "           lwd = 2, \n",
    "           cex = 1.2)\n",
    "    \n",
    "    detach(.)  # Undo the previous attach() command.\n",
    "\n",
    "    # AND THIS:\n",
    "      \n",
    "    # # Save the plot to PDF:\n",
    "    # dev.off()\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8c7f0-4226-4e6d-b758-aadcc6c34986",
   "metadata": {},
   "source": [
    "Create the histogram of the residual distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf2e4d-ab48-4a33-a0c4-18ad5d5c3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the residuals:\n",
    "\n",
    "# Find the best model (any metric will do, as they all agree):\n",
    "model_evaluation %>%\n",
    "      filter(r2c == max(r2c)) %>% select(model)\n",
    "\n",
    "hist_model <- models[[\"sjøtemperatur_cos * lat_sin * lat_sjøtemperatur * cos_sjøtemperatur * lat_sjøtemperatur * sin\"]]\n",
    "\n",
    "hist(residuals(hist_model), \n",
    "     freq = FALSE,\n",
    "     xlab = \"Residuals\",\n",
    "     main = \"Distribution of the residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d0a9e-8397-4521-a60c-53914c3c14b9",
   "metadata": {},
   "source": [
    "Explore the distribution of the data. The data are strongly right-skewed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf060a1-2d6e-49fe-ab3e-c0aaedfc1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sequence of values based on the fitted distribution\n",
    "x <- seq(0, max(working_df$voksne_hunnlus + 0.01), length.out = 1000)\n",
    "\n",
    "# Plot histogram of the data\n",
    "hist(working_df$voksne_hunnlus + 0.01, freq = FALSE, xlim = c(0, max(2)), breaks = 200,\n",
    "     main = \"Fitted Log-Normal distribution\",\n",
    "     xlab = \"Distribution\")\n",
    "\n",
    "# Add the fitted log-normal density curve\n",
    "curve(dlnorm(x, meanlog = fit$estimate[\"meanlog\"], sdlog = fit$estimate[\"sdlog\"]), \n",
    "      col = \"blue\", lwd = 2, add = TRUE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
